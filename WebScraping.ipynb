{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import requests",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "ename": "<class 'ModuleNotFoundError'>",
          "evalue": "No module named 'requests'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'requests'"
          ],
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "standings_url = \"https://fbref.com/en/comps/9/Premier-League-Stats\"",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "data = requests.get(standings_url)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from bs4 import BeautifulSoup",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "soup = BeautifulSoup(data.text)\nstandings_table = soup.select('table.stats_table')[0]\nlinks = standings_table.find_all('a')\nlinks = [l.get(\"href\") for l in links]\nlinks = [l for l in links if '/squads/' in l]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "team_urls = [f\"https://fbref.com{l}\" for l in links]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "data = requests.get(team_urls[0])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nmatches = pd.read_html(data.text, match=\"Scores & Fixtures\")[0]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "soup = BeautifulSoup(data.text)\nlinks = soup.find_all('a')\nlinks = [l.get(\"href\") for l in links]\nlinks = [l for l in links if l and 'all_comps/shooting/' in l]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "data = requests.get(f\"https://fbref.com{links[0]}\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "shooting = pd.read_html(data.text, match=\"Shooting\")[0]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "shooting.head()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "shooting.columns = shooting.columns.droplevel()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "team_data = matches.merge(shooting[[\"Date\", \"Sh\", \"SoT\", \"Dist\", \"FK\", \"PK\", \"PKatt\"]], on=\"Date\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "team_data.head()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "years = list(range(2022, 2020, -1))\nall_matches = []",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "standings_url = \"https://fbref.com/en/comps/9/Premier-League-Stats\"",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import time\nfor year in years:\n    data = requests.get(standings_url)\n    soup = BeautifulSoup(data.text)\n    standings_table = soup.select('table.stats_table')[0]\n\n    links = [l.get(\"href\") for l in standings_table.find_all('a')]\n    links = [l for l in links if '/squads/' in l]\n    team_urls = [f\"https://fbref.com{l}\" for l in links]\n    \n    previous_season = soup.select(\"a.prev\")[0].get(\"href\")\n    standings_url = f\"https://fbref.com{previous_season}\"\n    \n    for team_url in team_urls:\n        team_name = team_url.split(\"/\")[-1].replace(\"-Stats\", \"\").replace(\"-\", \" \")\n        data = requests.get(team_url)\n        matches = pd.read_html(data.text, match=\"Scores & Fixtures\")[0]\n        soup = BeautifulSoup(data.text)\n        links = [l.get(\"href\") for l in soup.find_all('a')]\n        links = [l for l in links if l and 'all_comps/shooting/' in l]\n        data = requests.get(f\"https://fbref.com{links[0]}\")\n        shooting = pd.read_html(data.text, match=\"Shooting\")[0]\n        shooting.columns = shooting.columns.droplevel()\n        try:\n            team_data = matches.merge(shooting[[\"Date\", \"Sh\", \"SoT\", \"Dist\", \"FK\", \"PK\", \"PKatt\"]], on=\"Date\")\n        except ValueError:\n            continue\n        team_data = team_data[team_data[\"Comp\"] == \"Premier League\"]\n        \n        team_data[\"Season\"] = year\n        team_data[\"Team\"] = team_name\n        all_matches.append(team_data)\n        time.sleep(1)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "len(all_matches)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "match_df = pd.concat(all_matches)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "match_df.columns = [c.lower() for c in match_df.columns]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "match_df",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "match_df.to_csv(\"matches.csv\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}